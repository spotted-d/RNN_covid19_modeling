{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and EDA: State Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Append path to import helper modules\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from utilities import states_to_abbrev, abbrev_to_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There's a ton of columns, but after reading some stuff up, it looks like\n",
    "the \"dry bulb\" temperature is the temperature that is meaningful.\n",
    "\"\"\"\n",
    "columns = [\"STATION\", \"DATE\", \"REPORT_TYPE\", \"SOURCE\", \"AWND\", \"BackupDirection\", \"BackupDistance\", \"BackupDistanceUnit\", \"BackupElements\", \"BackupElevation\", \"BackupElevationUnit\", \"BackupEquipment\", \"BackupLatitude\", \"BackupLongitude\", \"BackupName\", \"CDSD\", \"CLDD\", \"DSNW\", \"DailyAverageDewPointTemperature\", \"DailyAverageDryBulbTemperature\", \"DailyAverageRelativeHumidity\", \"DailyAverageSeaLevelPressure\", \"DailyAverageStationPressure\", \"DailyAverageWetBulbTemperature\", \"DailyAverageWindSpeed\", \"DailyCoolingDegreeDays\", \"DailyDepartureFromNormalAverageTemperature\", \"DailyHeatingDegreeDays\", \"DailyMaximumDryBulbTemperature\", \"DailyMinimumDryBulbTemperature\", \"DailyPeakWindDirection\", \"DailyPeakWindSpeed\", \"DailyPrecipitation\", \"DailySnowDepth\", \"DailySnowfall\", \"DailySustainedWindDirection\", \"DailySustainedWindSpeed\", \"DailyWeather\", \"HDSD\", \"HTDD\", \"HeavyFog\", \"HourlyAltimeterSetting\", \"HourlyDewPointTemperature\", \"HourlyDryBulbTemperature\", \"HourlyPrecipitation\", \"HourlyPresentWeatherType\", \"HourlyPressureChange\", \"HourlyPressureTendency\", \"HourlyRelativeHumidity\", \"HourlySeaLevelPressure\", \"HourlySkyConditions\", \"HourlyStationPressure\", \"HourlyVisibility\", \"HourlyWetBulbTemperature\", \"HourlyWindDirection\", \"HourlyWindGustSpeed\", \"HourlyWindSpeed\", \"MonthlyAverageRH\", \"MonthlyDaysWithGT001Precip\", \"MonthlyDaysWithGT010Precip\", \"MonthlyDaysWithGT32Temp\", \"MonthlyDaysWithGT90Temp\", \"MonthlyDaysWithLT0Temp\", \"MonthlyDaysWithLT32Temp\", \"MonthlyDepartureFromNormalAverageTemperature\", \"MonthlyDepartureFromNormalCoolingDegreeDays\", \"MonthlyDepartureFromNormalHeatingDegreeDays\", \"MonthlyDepartureFromNormalMaximumTemperature\", \"MonthlyDepartureFromNormalMinimumTemperature\", \"MonthlyDepartureFromNormalPrecipitation\", \"MonthlyDewpointTemperature\", \"MonthlyGreatestPrecip\", \"MonthlyGreatestPrecipDate\", \"MonthlyGreatestSnowDepth\", \"MonthlyGreatestSnowDepthDate\", \"MonthlyGreatestSnowfall\", \"MonthlyGreatestSnowfallDate\", \"MonthlyMaxSeaLevelPressureValue\", \"MonthlyMaxSeaLevelPressureValueDate\", \"MonthlyMaxSeaLevelPressureValueTime\", \"MonthlyMaximumTemperature\", \"MonthlyMeanTemperature\", \"MonthlyMinSeaLevelPressureValue\", \"MonthlyMinSeaLevelPressureValueDate\", \"MonthlyMinSeaLevelPressureValueTime\", \"MonthlyMinimumTemperature\", \"MonthlySeaLevelPressure\", \"MonthlyStationPressure\", \"MonthlyTotalLiquidPrecipitation\", \"MonthlyTotalSnowfall\", \"MonthlyWetBulb\", \"NormalsCoolingDegreeDay\", \"NormalsHeatingDegreeDay\", \"REM\", \"REPORT_TYPE\", \"SOURCE\", \"ShortDurationEndDate005\", \"ShortDurationEndDate010\", \"ShortDurationEndDate015\", \"ShortDurationEndDate020\", \"ShortDurationEndDate030\", \"ShortDurationEndDate045\", \"ShortDurationEndDate060\", \"ShortDurationEndDate080\", \"ShortDurationEndDate100\", \"ShortDurationEndDate120\", \"ShortDurationEndDate150\", \"ShortDurationEndDate180\", \"ShortDurationPrecipitationValue005\", \"ShortDurationPrecipitationValue010\", \"ShortDurationPrecipitationValue015\", \"ShortDurationPrecipitationValue020\", \"ShortDurationPrecipitationValue030\", \"ShortDurationPrecipitationValue045\", \"ShortDurationPrecipitationValue060\", \"ShortDurationPrecipitationValue080\", \"ShortDurationPrecipitationValue100\", \"ShortDurationPrecipitationValue120\", \"ShortDurationPrecipitationValue150\", \"ShortDurationPrecipitationValue180\", \"Sunrise\", \"Sunset\", \"TStorms\", \"WindEquipmentChangeDate\"]\n",
    "keep = set([\"STATION\", \"REPORT_TYPE\", \"SOURCE\", \"AWND\", \"DailyAverageDryBulbTemperature\", \"HourlyDryBulbTemperature\"])\n",
    "columns_to_remove = set(columns).difference(keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (19,25,26,27,28,29,30,31,32,35,36,37,41,42,43,44,45,48,49,50,51,52,53,54,55,56,58,59,68,69,71,72,85,88,93,96,97,98,99,100,101,102,103,104,105,106,107,114,117,119,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (3,5,7,8,11,14,19,25,26,27,28,29,30,31,32,33,34,35,36,37,41,42,43,44,45,48,49,50,51,52,53,54,55,56,58,59,60,69,71,72,76,88,93,95,96,97,98,99,100,101,102,103,104,105,106,107,117,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (5,7,8,11,14,19,25,26,27,28,29,30,31,32,33,34,35,36,37,41,42,43,44,45,48,49,50,51,52,53,54,55,56,58,59,69,71,72,73,75,76,88,89,93,96,97,98,99,100,101,102,103,104,105,106,107,113,114,117,119,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0,3,19,25,26,27,29,30,31,32,37,42,43,44,45,48,50,51,52,53,54,55,56,69,71,72,88,93,95,96,97,98,99,100,101,102,103,104,105,106,107,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0,3,5,7,8,11,14,30,31,32,37,42,44,45,48,50,53,55,56,58,59,69,71,72,88,95,96,97,98,99,100,101,102,103,104,105,106,107,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/Emily/opt/anaconda3/envs/cs109b/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Concat all the government weather data together.\n",
    "\"\"\"\n",
    "RAW_DATA_DIR = \"../data/raw_data/\"\n",
    "csv_data = []\n",
    "\n",
    "for i in range(1, 7):\n",
    "    csv_data.append(pd.read_csv(f\"{RAW_DATA_DIR}state_weather_{i}.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>REPORT_TYPE.1</th>\n",
       "      <th>SOURCE.1</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72216013869</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 00:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72216013869</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 01:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72216013869</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 02:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72216013869</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 03:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72216013869</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-01-01 04:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36666</th>\n",
       "      <td>99999904138</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>2020-05-06 20:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36667</th>\n",
       "      <td>99999904138</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>2020-05-06 20:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36668</th>\n",
       "      <td>99999904138</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>2020-05-06 20:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36669</th>\n",
       "      <td>99999904138</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>2020-05-06 20:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36670</th>\n",
       "      <td>99999904138</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>CRN05</td>\n",
       "      <td>I</td>\n",
       "      <td>2020-05-06 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471516 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id REPORT_TYPE SOURCE  AWND DailyAverageDryBulbTemperature  \\\n",
       "0      72216013869       FM-15      7   NaN                            NaN   \n",
       "1      72216013869       FM-15      7   NaN                            NaN   \n",
       "2      72216013869       FM-15      7   NaN                            NaN   \n",
       "3      72216013869       FM-15      7   NaN                            NaN   \n",
       "4      72216013869       FM-15      7   NaN                            NaN   \n",
       "...            ...         ...    ...   ...                            ...   \n",
       "36666  99999904138       CRN05      I   NaN                            NaN   \n",
       "36667  99999904138       CRN05      I   NaN                            NaN   \n",
       "36668  99999904138       CRN05      I   NaN                            NaN   \n",
       "36669  99999904138       CRN05      I   NaN                            NaN   \n",
       "36670  99999904138       CRN05      I   NaN                            NaN   \n",
       "\n",
       "       HourlyDryBulbTemperature REPORT_TYPE.1 SOURCE.1                date  \n",
       "0                          40.0         FM-15        7 2020-01-01 00:53:00  \n",
       "1                          39.0         FM-15        7 2020-01-01 01:53:00  \n",
       "2                          37.0         FM-15        7 2020-01-01 02:53:00  \n",
       "3                          37.0         FM-15        7 2020-01-01 03:53:00  \n",
       "4                          36.0         FM-15        7 2020-01-01 04:53:00  \n",
       "...                         ...           ...      ...                 ...  \n",
       "36666                      47.0         CRN05        I 2020-05-06 20:40:00  \n",
       "36667                      47.0         CRN05        I 2020-05-06 20:45:00  \n",
       "36668                      47.0         CRN05        I 2020-05-06 20:50:00  \n",
       "36669                      46.0         CRN05        I 2020-05-06 20:55:00  \n",
       "36670                      44.0         CRN05        I 2020-05-06 21:00:00  \n",
       "\n",
       "[471516 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states_weather = pd.concat(csv_data, axis=0)\n",
    "states_weather = states_weather.rename(columns={\"STATION\": \"station_id\"})\n",
    "states_weather[\"date\"] = pd.to_datetime(states_weather[\"DATE\"], infer_datetime_format=True)\n",
    "states_weather = states_weather.drop(columns=columns_to_remove)\n",
    "\n",
    "# An entire dataset for Utah is problematic. Drop it.\n",
    "states_weather = states_weather[states_weather[\"station_id\"] != \"A0001603036\"]\n",
    "\n",
    "states_weather[\"HourlyDryBulbTemperature\"] = pd.to_numeric(\n",
    "    states_weather[\"HourlyDryBulbTemperature\"], errors=\"coerce\"\n",
    ")\n",
    "states_weather = states_weather.dropna(subset=[\"HourlyDryBulbTemperature\"])\n",
    "\n",
    "display(states_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wban_id</th>\n",
       "      <th>state</th>\n",
       "      <th>station_meta</th>\n",
       "      <th>lattitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999</td>\n",
       "      <td></td>\n",
       "      <td>007018</td>\n",
       "      <td>+00.000 +</td>\n",
       "      <td>+000.000 +</td>\n",
       "      <td>+7018.0</td>\n",
       "      <td>WXPOD 7018</td>\n",
       "      <td>701899999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99999</td>\n",
       "      <td></td>\n",
       "      <td>007026</td>\n",
       "      <td>+00.000 +</td>\n",
       "      <td>+000.000 +</td>\n",
       "      <td>+7026.0</td>\n",
       "      <td>WXPOD 7026</td>\n",
       "      <td>702699999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999</td>\n",
       "      <td></td>\n",
       "      <td>007070</td>\n",
       "      <td>+00.000 +</td>\n",
       "      <td>+000.000 +</td>\n",
       "      <td>+7070.0</td>\n",
       "      <td>WXPOD 7070</td>\n",
       "      <td>707099999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999</td>\n",
       "      <td></td>\n",
       "      <td>008260</td>\n",
       "      <td>+00.000 +</td>\n",
       "      <td>+000.000 +</td>\n",
       "      <td>+0000.0</td>\n",
       "      <td>WXPOD8270</td>\n",
       "      <td>826099999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99999</td>\n",
       "      <td></td>\n",
       "      <td>008268</td>\n",
       "      <td>+32.950 +</td>\n",
       "      <td>+065.567 +</td>\n",
       "      <td>+1156.7</td>\n",
       "      <td>WXPOD8278</td>\n",
       "      <td>826899999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29703</th>\n",
       "      <td>96405</td>\n",
       "      <td>AK</td>\n",
       "      <td>999999</td>\n",
       "      <td>+60.473 -</td>\n",
       "      <td>-145.354 +</td>\n",
       "      <td>+0025.3</td>\n",
       "      <td>CORDOVA 14 ESE</td>\n",
       "      <td>99999996405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29704</th>\n",
       "      <td>96406</td>\n",
       "      <td>AK</td>\n",
       "      <td>999999</td>\n",
       "      <td>+64.502 -</td>\n",
       "      <td>-154.130 +</td>\n",
       "      <td>+0078.9</td>\n",
       "      <td>RUBY 44 ESE</td>\n",
       "      <td>99999996406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29705</th>\n",
       "      <td>96407</td>\n",
       "      <td>AK</td>\n",
       "      <td>999999</td>\n",
       "      <td>+66.562 -</td>\n",
       "      <td>-159.004 +</td>\n",
       "      <td>+0006.7</td>\n",
       "      <td>SELAWIK 28 E</td>\n",
       "      <td>99999996407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29706</th>\n",
       "      <td>96408</td>\n",
       "      <td>AK</td>\n",
       "      <td>999999</td>\n",
       "      <td>+63.452 -</td>\n",
       "      <td>-150.875 +</td>\n",
       "      <td>+0678.2</td>\n",
       "      <td>DENALI 27 N</td>\n",
       "      <td>99999996408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29707</th>\n",
       "      <td>96409</td>\n",
       "      <td>AK</td>\n",
       "      <td>999999</td>\n",
       "      <td>+68.648 -</td>\n",
       "      <td>-149.399 +</td>\n",
       "      <td>+0750.1</td>\n",
       "      <td>TOOLIK LAKE 5 ENE</td>\n",
       "      <td>99999996409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29708 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wban_id state station_meta  lattitude   longitude elevation  \\\n",
       "0        99999             007018  +00.000 +  +000.000 +   +7018.0   \n",
       "1        99999             007026  +00.000 +  +000.000 +   +7026.0   \n",
       "2        99999             007070  +00.000 +  +000.000 +   +7070.0   \n",
       "3        99999             008260  +00.000 +  +000.000 +   +0000.0   \n",
       "4        99999             008268  +32.950 +  +065.567 +   +1156.7   \n",
       "...        ...   ...          ...        ...         ...       ...   \n",
       "29703    96405    AK       999999  +60.473 -  -145.354 +   +0025.3   \n",
       "29704    96406    AK       999999  +64.502 -  -154.130 +   +0078.9   \n",
       "29705    96407    AK       999999  +66.562 -  -159.004 +   +0006.7   \n",
       "29706    96408    AK       999999  +63.452 -  -150.875 +   +0678.2   \n",
       "29707    96409    AK       999999  +68.648 -  -149.399 +   +0750.1   \n",
       "\n",
       "            station_name   station_id  \n",
       "0             WXPOD 7018    701899999  \n",
       "1             WXPOD 7026    702699999  \n",
       "2             WXPOD 7070    707099999  \n",
       "3              WXPOD8270    826099999  \n",
       "4              WXPOD8278    826899999  \n",
       "...                  ...          ...  \n",
       "29703     CORDOVA 14 ESE  99999996405  \n",
       "29704        RUBY 44 ESE  99999996406  \n",
       "29705       SELAWIK 28 E  99999996407  \n",
       "29706        DENALI 27 N  99999996408  \n",
       "29707  TOOLIK LAKE 5 ENE  99999996409  \n",
       "\n",
       "[29708 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ughhhh. The text file for the station IDs is so inconsistently formatted,\n",
    "so we can't just read it with a pandas or np and a basic delimiter.\n",
    "\n",
    "The station metadata is global, but we want to extract \n",
    "IDS for all of the US states only.\n",
    "\"\"\"\n",
    "\n",
    "def extract_station_metadata():\n",
    "    station_df = []\n",
    "    station_ids = open(\"../data/raw_data/station_metadata.txt\", \"r\")\n",
    "\n",
    "    # state start index\n",
    "    ss_index = 47\n",
    "    wban_index = 7\n",
    "    for i, line in enumerate(station_ids):\n",
    "        # skip header\n",
    "        if i == 0:\n",
    "            continue\n",
    "        state = line[ss_index: ss_index + 3].strip()\n",
    "        if state.isspace():\n",
    "            continue\n",
    "        else:\n",
    "            # It's a US state. Start parsing.\n",
    "            wban_id = line[wban_index: wban_index + 6].strip()\n",
    "            station_meta = line[0:7].strip()\n",
    "            # Because why not?\n",
    "            lattitude = line[57:66].strip()\n",
    "            longitude = line[65:75].strip()\n",
    "            elevation = line[74:82].strip()\n",
    "            station_name = line[13:43].strip()\n",
    "            station_id = f\"{station_meta}{wban_id}\"\n",
    "            try:\n",
    "                # The weather data has the station ID as an integer. \n",
    "                # Data types must match up in the join, so throw out anything that's not\n",
    "                # castable to an int.\n",
    "                station_id = int(station_id)\n",
    "            except:\n",
    "                continue\n",
    "            row = {\n",
    "                \"wban_id\": int(wban_id),\n",
    "                \"state\": state,\n",
    "                \"station_meta\": station_meta,\n",
    "                \"lattitude\": lattitude,\n",
    "                \"longitude\": longitude,\n",
    "                \"elevation\": elevation,\n",
    "                \"station_name\": station_name,\n",
    "                \"station_id\": station_id\n",
    "            }\n",
    "            station_df.append(row)\n",
    "    result = pd.DataFrame(station_df)\n",
    "    return result\n",
    "\n",
    "station_df = extract_station_metadata()\n",
    "display(station_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = states_weather.merge(station_df, left_on=\"station_id\", right_on=\"station_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['District of Columbia', 'Puerto Rico']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, let's check to be sure there's data for all states. Hopefully we are not missing any!\n",
    "\"\"\"\n",
    "grouped_states = states_df.groupby([\"station_name\", \"station_id\", \"state\"]).agg(\n",
    "    {\"station_name\": \"first\", \"station_id\": \"first\", \"state\": \"first\"}\n",
    ").reset_index(drop=True)\n",
    "states_list = set(grouped_states[\"state\"].values)\n",
    "\n",
    "all_states = [\n",
    "    'AL', 'AK', 'AS', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'GU', 'HI', \n",
    "    'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', \n",
    "    'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'MP', 'OH', 'OK', 'OR', 'PA', \n",
    "    'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VI', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "]\n",
    "\n",
    "missing_states = set(all_states).difference(states_list)\n",
    "ms_full = [abbrev_to_states[x] for x in list(missing_states)]\n",
    "print(ms_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Missing states above. \n",
    "\n",
    "There are some errors with the datasets from GOV, marked with a \"warning\" sign, so\n",
    "I will re-investigate. Since I had to download these states one-by-one, will investigate after I get an initial weather \n",
    "dataset crunched.\n",
    "\"\"\"\n",
    "cleaned_weather_data = states_df.groupby([\"state\", states_df[\"date\"].dt.year, states_df[\"date\"].dt.month, states_df[\"date\"].dt.day]).agg({\n",
    "    \"state\": \"first\",\n",
    "    \"date\": \"first\",\n",
    "    \"HourlyDryBulbTemperature\": \"mean\"\n",
    "}).rename(columns={\"HourlyDryBulbTemperature\": \"average_temperature\"}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-01-01 00:42:00</td>\n",
       "      <td>29.145161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-01-02 00:56:00</td>\n",
       "      <td>26.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-01-03 01:56:00</td>\n",
       "      <td>23.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-01-04 00:04:00</td>\n",
       "      <td>33.174603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-01-05 00:29:00</td>\n",
       "      <td>27.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-05-02 00:29:00</td>\n",
       "      <td>42.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-05-03 00:53:00</td>\n",
       "      <td>44.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-05-04 00:53:00</td>\n",
       "      <td>42.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6668</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-05-05 00:53:00</td>\n",
       "      <td>42.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-05-06 00:53:00</td>\n",
       "      <td>45.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6670 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state                date  average_temperature\n",
       "0       AK 2020-01-01 00:42:00            29.145161\n",
       "1       AK 2020-01-02 00:56:00            26.428571\n",
       "2       AK 2020-01-03 01:56:00            23.725000\n",
       "3       AK 2020-01-04 00:04:00            33.174603\n",
       "4       AK 2020-01-05 00:29:00            27.931034\n",
       "...    ...                 ...                  ...\n",
       "6665    WY 2020-05-02 00:29:00            42.972973\n",
       "6666    WY 2020-05-03 00:53:00            44.666667\n",
       "6667    WY 2020-05-04 00:53:00            42.458333\n",
       "6668    WY 2020-05-05 00:53:00            42.500000\n",
       "6669    WY 2020-05-06 00:53:00            45.583333\n",
       "\n",
       "[6670 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cleaned_weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to pickle file\n",
    "pickle.dump(cleaned_weather_data, open(\"../data/daily_average_temp_by_state.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
